#!/usr/bin/env python3
"""
Vision Handler Module with MediaPipe Tasks API

–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ —Ä—É–∫ —Å –∫–∞–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑—É—è –Ω–æ–≤—ã–π MediaPipe Tasks API.
–í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
"""

import os
import cv2
import json
import time
import threading
import numpy as np
from typing import Optional, Dict, Any, List, Tuple, Callable
from pathlib import Path

# –ò–º–ø–æ—Ä—Ç—ã —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
mediapipe = None
PIL = None

try:
    import mediapipe as mp
    from mediapipe.tasks import python
    from mediapipe.tasks.python import vision
    mediapipe = True
except ImportError:
    mediapipe = None
    mp = None
    python = None
    vision = None

try:
    from PIL import Image
    PIL = True
except ImportError:
    PIL = None

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
MISSING_DEPS = []
if mediapipe is None:
    MISSING_DEPS.append('mediapipe')
if cv2 is None:
    MISSING_DEPS.append('opencv-python')

if MISSING_DEPS:
    print(f"‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç vision –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {', '.join(MISSING_DEPS)}")
    print("–î–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install " + ' '.join(MISSING_DEPS))

class VisionConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è vision –º–æ–¥—É–ª—è"""
    
    def __init__(self, config_path: Optional[str] = None):
        # –ò–º–ø–æ—Ä—Ç –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ config.py
        try:
            import config as app_config
        except ImportError:
            raise ImportError("‚ùå config.py –Ω–µ –Ω–∞–π–¥–µ–Ω! –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª config.py —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏.")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–∞–º–µ—Ä—ã
        self.camera_device_id = app_config.CAMERA_DEVICE_ID
        self.camera_fps = app_config.CAMERA_FPS
        self.camera_resolution = tuple(app_config.CAMERA_RESOLUTION)
        self.gesture_detection = app_config.GESTURE_DETECTION_ENABLED
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ MediaPipe Tasks
        self.min_hand_detection_confidence = app_config.MEDIAPIPE_MIN_DETECTION_CONFIDENCE
        self.min_hand_presence_confidence = app_config.MEDIAPIPE_MIN_TRACKING_CONFIDENCE
        self.min_tracking_confidence = app_config.MEDIAPIPE_MIN_TRACKING_CONFIDENCE
        self.max_num_hands = app_config.MEDIAPIPE_MAX_NUM_HANDS
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        self.frame_skip = app_config.FRAME_SKIP
        self.analysis_interval = app_config.GESTURE_ANALYSIS_INTERVAL
        self.gesture_confidence = app_config.GESTURE_CONFIDENCE
        self.gesture_confirmation_time = app_config.GESTURE_CONFIRMATION_TIME
        self.gesture_inactivity_timeout = app_config.GESTURE_INACTIVITY_TIMEOUT
        
        # –í–∫–ª—é—á–µ–Ω–∏–µ/–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π
        self.real_time_analysis = app_config.REAL_TIME_ANALYSIS
        self.gesture_recognition = app_config.GESTURE_RECOGNITION
        self.hand_tracking = app_config.HAND_TRACKING
        
        # –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        self.model_path = self._get_model_path()
        
        print("‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Vision –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ config.py")
    
    def _get_model_path(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª–∏ MediaPipe Tasks"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –±–µ–∑ —Ä—É—Å—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        safe_model_path = r"C:\temp_mediapipe\gesture_recognizer.task"
        
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        possible_paths = [
            Path(safe_model_path),
            Path(__file__).parent / "models" / "gesture_recognizer.task",
            Path.home() / ".mediapipe" / "gesture_recognizer.task",
            Path(__file__).parent / "gesture_recognizer.task"
        ]
        
        for path in possible_paths:
            if path.exists():
                return str(path)
        
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        return str(Path(__file__).parent / "gesture_recognizer.task")

class MediaPipeGestureRecognizer:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é MediaPipe Tasks API"""
    
    def __init__(self, config: VisionConfig):
        self.config = config
        self.recognizer = None
        
        # –ò—Å—Ç–æ—Ä–∏—è –∂–µ—Å—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.gesture_history = []
        self.last_detection_time = 0
        
        self._initialize_mediapipe()
    
    def _initialize_mediapipe(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe Tasks"""
        if not mediapipe:
            print("‚ùå MediaPipe –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏
            model_path = self.config.model_path
            if not Path(model_path).exists():
                print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
                print("üîÑ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å gesture_recognizer.task")
                print("   –°—Å—ã–ª–∫–∞: https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task")
                return
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è MediaPipe Tasks
            base_options = python.BaseOptions(model_asset_path=model_path)  # type: ignore
            
            # –û–ø—Ü–∏–∏ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤
            options = vision.GestureRecognizerOptions(  # type: ignore
                base_options=base_options,
                running_mode=vision.RunningMode.IMAGE,  # type: ignore  # –î–ª—è –Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∂–∏–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                num_hands=self.config.max_num_hands,
                min_hand_detection_confidence=self.config.min_hand_detection_confidence,
                min_hand_presence_confidence=self.config.min_hand_presence_confidence,
                min_tracking_confidence=self.config.min_tracking_confidence
            )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—è
            self.recognizer = vision.GestureRecognizer.create_from_options(options)  # type: ignore
            
            print("‚úÖ MediaPipe Tasks –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MediaPipe Tasks: {e}")
    
    def detect_hand_gestures(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """
        –î–µ—Ç–µ–∫—Ü–∏—è –∂–µ—Å—Ç–æ–≤ —Ä—É–∫ –≤ –∫–∞–¥—Ä–µ –∏—Å–ø–æ–ª—å–∑—É—è MediaPipe Tasks
        """
        current_time = time.time()
        if current_time - self.last_detection_time < self.config.analysis_interval:
            return []
        
        self.last_detection_time = current_time
        
        if self.recognizer is None:
            return []
        
        gestures = []
        
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenCV –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ MediaPipe Image
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            if not mp:
                return []
                
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ MediaPipe Image
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∂–µ—Å—Ç–æ–≤
            result = self.recognizer.recognize(mp_image)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if result.gestures:
                for i, gesture_list in enumerate(result.gestures):
                    if gesture_list:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –∂–µ—Å—Ç—ã
                        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä—É–∫–µ (–ø—Ä–∞–≤–∞—è/–ª–µ–≤–∞—è)
                        handedness = result.handedness[i][0] if result.handedness and len(result.handedness) > i else None
                        hand_label = handedness.category_name.lower() if handedness else "unknown"
                        hand_confidence = handedness.score if handedness else 0.0
                        
                        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∂–µ—Å—Ç–µ
                        gesture = gesture_list[0]  # –ë–µ—Ä–µ–º –∂–µ—Å—Ç —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                        
                        # –û—Ä–∏–µ–Ω—Ç–∏—Ä—ã —Ä—É–∫–∏
                        landmarks = []
                        if result.hand_landmarks and len(result.hand_landmarks) > i:
                            for landmark in result.hand_landmarks[i]:
                                landmarks.append([landmark.x, landmark.y, landmark.z])
                        
                        if gesture.score > self.config.gesture_confidence:
                            gesture_data = {
                                'type': gesture.category_name.lower(),
                                'hand': hand_label,
                                'confidence': gesture.score,
                                'hand_confidence': hand_confidence,
                                'landmarks': landmarks,
                                'timestamp': current_time,
                                'description': f"{gesture.category_name} - {hand_label} —Ä—É–∫–∞"
                            }
                            gestures.append(gesture_data)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –∂–µ—Å—Ç–æ–≤: {e}")
        
        return gestures
    
    def get_gesture_description(self, gesture: Dict[str, Any]) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∂–µ—Å—Ç–∞
        """
        gesture_descriptions = {
            "thumb_up": "üëç –ë–æ–ª—å—à–æ–π –ø–∞–ª–µ—Ü –≤–≤–µ—Ä—Ö",
            "thumb_down": "üëé –ë–æ–ª—å—à–æ–π –ø–∞–ª–µ—Ü –≤–Ω–∏–∑",
            "pointing_up": "‚òùÔ∏è –£–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –ø–∞–ª–µ—Ü –≤–≤–µ—Ä—Ö", 
            "open_palm": "‚úã –û—Ç–∫—Ä—ã—Ç–∞—è –ª–∞–¥–æ–Ω—å",
            "closed_fist": "‚úä –ö—É–ª–∞–∫",
            "victory": "‚úåÔ∏è –ó–Ω–∞–∫ –ø–æ–±–µ–¥—ã",
            "iloveyou": "ü§ü –ó–Ω–∞–∫ '–Ø –ª—é–±–ª—é —Ç–µ–±—è'",
            "none": "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∂–µ—Å—Ç",
            "unknown": "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∂–µ—Å—Ç"
        }
        
        gesture_type = gesture.get('type', 'unknown')
        base_description = gesture_descriptions.get(gesture_type, f"–ñ–µ—Å—Ç: {gesture_type}")
        hand_info = f" ({gesture['hand']} —Ä—É–∫–∞)"
        confidence_info = f" [–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {gesture['confidence']:.2f}]"
        
        return base_description + hand_info + confidence_info
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ MediaPipe"""
        if self.recognizer:
            self.recognizer.close()

class CameraHandler:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–∞–º–µ—Ä–æ–π"""
    
    def __init__(self, config: VisionConfig):
        self.config = config
        self.camera = None
        self.is_recording = False
        self.frame_callback = None
        self.current_frame = None
        self.capture_thread = None  # –î–æ–±–∞–≤–ª–µ–Ω–æ: —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Ç–æ–∫ –∑–∞—Ö–≤–∞—Ç–∞
        self._initialize_camera()
    
    def _initialize_camera(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã"""
        try:
            self.camera = cv2.VideoCapture(self.config.camera_device_id)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã
            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, self.config.camera_resolution[0])
            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, self.config.camera_resolution[1])
            self.camera.set(cv2.CAP_PROP_FPS, self.config.camera_fps)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–∫—Ä—ã—Ç–∏—è
            if not self.camera.isOpened():
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
            
            print(f"üìπ –ö–∞–º–µ—Ä–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {self.config.camera_resolution} @ {self.config.camera_fps}fps")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞–º–µ—Ä—ã: {e}")
            self.camera = None
    
    def start_capture(self, frame_callback: Optional[Callable] = None):
        """–ó–∞–ø—É—Å–∫ –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ"""
        # –†–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É –µ—Å–ª–∏ –æ–Ω–∞ –±—ã–ª–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞
        if self.camera is None:
            print("üîÑ –†–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã...")
            self._initialize_camera()
            if self.camera is None:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–º–µ—Ä—É")
                return False
        
        if self.is_recording:
            print("‚ö†Ô∏è –ó–∞—Ö–≤–∞—Ç –≤–∏–¥–µ–æ —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
            return True
        
        self.frame_callback = frame_callback
        self.is_recording = True
        
        # –ó–∞–ø—É—Å–∫ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
        self.capture_thread = threading.Thread(target=self._capture_loop, daemon=True)
        self.capture_thread.start()
        
        print("üé• –ó–∞—Ö–≤–∞—Ç –≤–∏–¥–µ–æ –∑–∞–ø—É—â–µ–Ω")
        return True
    
    def stop_capture(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞ –≤–∏–¥–µ–æ –∏ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã"""
        self.is_recording = False
        
        # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–æ—Ç–æ–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞
        if self.capture_thread and self.capture_thread.is_alive():
            self.capture_thread.join(timeout=2.0)
        
        self.capture_thread = None  # –û–±–Ω—É–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Ç–æ–∫
        
        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∫–∞–º–µ—Ä—É
        if self.camera is not None:
            self.camera.release()
            self.camera = None
            print("üìπ –ö–∞–º–µ—Ä–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∞")
        
        self.current_frame = None
        print("‚èπÔ∏è  –ó–∞—Ö–≤–∞—Ç –≤–∏–¥–µ–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def _capture_loop(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∑–∞—Ö–≤–∞—Ç–∞ –∫–∞–¥—Ä–æ–≤"""
        frame_count = 0
        
        while self.is_recording and self.camera is not None:
            ret, frame = self.camera.read()
            
            if not ret:
                print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã")
                break
            
            # –ü—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ —Ä–µ—Å—É—Ä—Å–æ–≤
            frame_count += 1
            if frame_count % self.config.frame_skip != 0:
                continue
            
            self.current_frame = frame
            
            # –í—ã–∑–æ–≤ callback —Ñ—É–Ω–∫—Ü–∏–∏ –µ—Å–ª–∏ –∑–∞–¥–∞–Ω–∞
            if self.frame_callback:
                try:
                    self.frame_callback(frame)
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ callback: {e}")
            
            # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ FPS
            time.sleep(1.0 / self.config.camera_fps)
    
    def get_current_frame(self) -> Optional[np.ndarray]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞"""
        return self.current_frame
    
    def release(self):
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–∞–º–µ—Ä—ã"""
        self.stop_capture()
        if self.camera:
            self.camera.release()
            cv2.destroyAllWindows()

class VisionHandler:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å vision –º–æ–¥—É–ª–µ–º"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config = VisionConfig(config_path)
        self.camera_handler = CameraHandler(self.config)
        self.gesture_recognizer = MediaPipeGestureRecognizer(self.config)
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.is_vision_active = False
        self.is_paused = False  # –§–ª–∞–≥ –ø–∞—É–∑—ã (–Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–∞–º–µ—Ä—É, –ø—Ä–æ—Å—Ç–æ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º)
        self.last_analysis_time = 0
        self.analysis_results = []
        self.current_gestures = []
        
        # –õ–æ–≥–∏–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∂–µ—Å—Ç–æ–≤
        self.gesture_buffer = []  # –ë—É—Ñ–µ—Ä –∂–µ—Å—Ç–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —Å–µ–∫—É–Ω–¥
        self.last_gesture_time = time.time()  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ –∂–µ—Å—Ç–∞
        self.last_confirmed_gesture = None  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–π –∂–µ—Å—Ç
        self.gesture_callback = None  # Callback –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∂–µ—Å—Ç–∞
        
        print("üëÅÔ∏è  Vision –º–æ–¥—É–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.print_status()
    
    def print_status(self):
        """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç—É—Å–∞ vision –º–æ–¥—É–ª—è"""
        print(f"üìπ –ö–∞–º–µ—Ä–∞: {'‚úÖ' if self.camera_handler.camera else '‚ùå'}")
        print(f"ü§ñ MediaPipe Tasks: {'‚úÖ' if self.gesture_recognizer.recognizer else '‚ùå'}")
        print(f"üëã –î–µ—Ç–µ–∫—Ü–∏—è –∂–µ—Å—Ç–æ–≤: {'‚úÖ' if self.config.gesture_recognition else '‚ùå'}")
        
        if not self.gesture_recognizer.recognizer:
            print(f"üìÅ –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏: {self.config.model_path}")
            print("üí° –°–æ–≤–µ—Ç: –°–∫–∞—á–∞–π—Ç–µ gesture_recognizer.task –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã")
    
    def set_gesture_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ callback —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã—Ö –∂–µ—Å—Ç–æ–≤"""
        self.gesture_callback = callback
    
    def _check_gesture_confirmation(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∂–µ—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –±—É—Ñ–µ—Ä–∞"""
        if not self.gesture_buffer:
            return
        
        # –ü–æ–¥—Å—á—ë—Ç –∂–µ—Å—Ç–æ–≤ –ø–æ —Ç–∏–ø—É –≤ –±—É—Ñ–µ—Ä–µ
        gesture_counts = {}
        for gesture in self.gesture_buffer:
            gesture_type = gesture['type']  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: 'type' –≤–º–µ—Å—Ç–æ 'gesture'
            if gesture_type not in gesture_counts:
                gesture_counts[gesture_type] = 0
            gesture_counts[gesture_type] += 1
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –∂–µ—Å—Ç
        if gesture_counts:
            most_common_gesture = max(gesture_counts, key=gesture_counts.get)
            count = gesture_counts[most_common_gesture]
            
            # –ï—Å–ª–∏ –∂–µ—Å—Ç –ø–æ—è–≤–∏–ª—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑ (–º–∏–Ω–∏–º—É–º 3 —Ä–∞–∑–∞ –∑–∞ 1.5 —Å–µ–∫—É–Ω–¥—ã –ø—Ä–∏ 16fps = ~24 –∫–∞–¥—Ä–∞)
            # –ò —ç—Ç–æ –Ω–µ —Ç–æ—Ç –∂–µ –∂–µ—Å—Ç —á—Ç–æ –Ω–µ–¥–∞–≤–Ω–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–ª–∏ (—á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
            if count >= 3 and most_common_gesture != self.last_confirmed_gesture:
                # –ú–∞–ø–ø–∏–Ω–≥ –∂–µ—Å—Ç–æ–≤ –Ω–∞ —Ç–µ–∫—Å—Ç
                gesture_text_map = {
                    'open_palm': '–ü—Ä–∏–≤–µ—Ç',
                    'victory': '–ü–æ–±–µ–¥–∞',
                    'thumb_up': '–°—É–ø–µ—Ä',
                    'pointing_up': '–í–Ω–∏–º–∞–Ω–∏–µ'
                }
                
                if most_common_gesture in gesture_text_map:
                    confirmed_text = gesture_text_map[most_common_gesture]
                    print(f"‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω –∂–µ—Å—Ç: {most_common_gesture} ‚Üí '{confirmed_text}'")
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–π –∂–µ—Å—Ç
                    self.last_confirmed_gesture = most_common_gesture
                    
                    # –í—ã–∑—ã–≤–∞–µ–º callback –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                    if self.gesture_callback:
                        self.gesture_callback(confirmed_text)
                    
                    # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –ø–æ—Å–ª–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                    self.gesture_buffer = []
    
    def start_real_time_analysis(self, gesture_callback=None):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            if not self.config.real_time_analysis:
                print("‚ùå –ê–Ω–∞–ª–∏–∑ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª—é—á–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥–µ")
                return False
            
            if self.camera_handler.camera is None:
                print("‚ùå –ö–∞–º–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
                return False
            
            if self.gesture_recognizer.recognizer is None:
                print("‚ö†Ô∏è MediaPipe Tasks –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–∞–º–µ—Ä–∞ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –∂–µ—Å—Ç–æ–≤")
                # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º False - –∫–∞–º–µ—Ä–∞ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –∏ –±–µ–∑ –∂–µ—Å—Ç–æ–≤
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º callback –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω
            if gesture_callback:
                self.gesture_callback = gesture_callback
            
            # –°–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è
            self.gesture_buffer = []
            self.last_gesture_time = time.time()
            self.last_confirmed_gesture = None
            
            self.is_vision_active = True
            success = self.camera_handler.start_capture(self._frame_analysis_callback)
            
            if success:
                print("üîç –ê–Ω–∞–ª–∏–∑ –∂–µ—Å—Ç–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–ø—É—â–µ–Ω")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞—Ö–≤–∞—Ç —Å –∫–∞–º–µ—Ä—ã")
            return success
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def pause_analysis(self):
        """–ü—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ (–∫–∞–º–µ—Ä–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, –Ω–æ –∂–µ—Å—Ç—ã –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è)"""
        self.is_paused = True
        print("‚è∏Ô∏è –ê–Ω–∞–ª–∏–∑ –∂–µ—Å—Ç–æ–≤ –ø—Ä–∏–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω (–∫–∞–º–µ—Ä–∞ –∞–∫—Ç–∏–≤–Ω–∞)")
    
    def resume_analysis(self):
        """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –∂–µ—Å—Ç–æ–≤"""
        if self.is_vision_active:
            self.is_paused = False
            self.last_gesture_time = time.time()  # –°–±—Ä–æ—Å —Ç–∞–π–º–µ—Ä–∞
            self.gesture_buffer = []  # –û—á–∏—Å—Ç–∫–∞ –±—É—Ñ–µ—Ä–∞
            print("‚ñ∂Ô∏è –ê–Ω–∞–ª–∏–∑ –∂–µ—Å—Ç–æ–≤ –≤–æ–∑–æ–±–Ω–æ–≤–ª—ë–Ω")
        else:
            print("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –Ω–µ –±—ã–ª –∑–∞–ø—É—â–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ start_real_time_analysis()")
    
    def stop_real_time_analysis(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        try:
            self.is_vision_active = False
            self.is_paused = False
            self.camera_handler.stop_capture()
            print("‚èπÔ∏è  –ê–Ω–∞–ª–∏–∑ –∂–µ—Å—Ç–æ–≤ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def _frame_analysis_callback(self, frame: np.ndarray):
        """Callback –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–¥—Ä–æ–≤"""
        current_time = time.time()
        
        try:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –Ω–∞ –ø–∞—É–∑–µ
            if self.is_paused:
                return
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –±–µ–∑–¥–µ–π—Å—Ç–≤–∏—è
            if current_time - self.last_gesture_time > self.config.gesture_inactivity_timeout:
                print(f"‚è∞ –¢–∞–π–º–∞—É—Ç –±–µ–∑–¥–µ–π—Å—Ç–≤–∏—è ({self.config.gesture_inactivity_timeout} —Å–µ–∫) - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∂–µ—Å—Ç–æ–≤")
                self.stop_real_time_analysis()
                return
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –∂–µ—Å—Ç–æ–≤
            gestures = []
            if self.config.gesture_recognition and self.gesture_recognizer.recognizer:
                gestures = self.gesture_recognizer.detect_hand_gestures(frame)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –∂–µ—Å—Ç–æ–≤
            self.current_gestures = gestures
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∂–µ—Å—Ç–æ–≤
            if gestures:
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∂–µ—Å—Ç–∞
                self.last_gesture_time = current_time
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∂–µ—Å—Ç—ã –≤ –±—É—Ñ–µ—Ä
                for gesture in gestures:
                    gesture['detected_at'] = current_time
                    self.gesture_buffer.append(gesture)
                    
                    description = self.gesture_recognizer.get_gesture_description(gesture)
                    print(f"üëã {description}")
                
                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∂–µ—Å—Ç—ã –∏–∑ –±—É—Ñ–µ—Ä–∞ (—Å—Ç–∞—Ä—à–µ —á–µ–º confirmation_time)
                self.gesture_buffer = [
                    g for g in self.gesture_buffer 
                    if current_time - g['detected_at'] <= self.config.gesture_confirmation_time
                ]
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –∂–µ—Å—Ç–∞
                self._check_gesture_confirmation()
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                result = {
                    'timestamp': current_time,
                    'gestures': gestures,
                    'frame_shape': frame.shape
                }
                
                self.analysis_results.append(result)
                
                # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏
                if len(self.analysis_results) > 20:
                    self.analysis_results.pop(0)
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–∞–¥—Ä–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def get_current_gestures(self) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–∏—Ö –∂–µ—Å—Ç–æ–≤"""
        return self.current_gestures
    
    def get_recent_analysis(self, count: int = 5) -> List[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        return self.analysis_results[-count:] if self.analysis_results else []
    
    def analyze_single_frame(self, prompt: str = "–ê–Ω–∞–ª–∏–∑ –∂–µ—Å—Ç–æ–≤") -> str:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ –∫–∞–¥—Ä–∞"""
        frame = self.camera_handler.get_current_frame()
        if frame is None:
            return "–ö–∞–¥—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        if self.gesture_recognizer.recognizer is None:
            return "MediaPipe Tasks –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        
        gestures = self.gesture_recognizer.detect_hand_gestures(frame)
        
        if not gestures:
            return "–ñ–µ—Å—Ç—ã –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"
        
        descriptions = []
        for gesture in gestures:
            desc = self.gesture_recognizer.get_gesture_description(gesture)
            descriptions.append(desc)
        
        return f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∂–µ—Å—Ç—ã: {', '.join(descriptions)}"
    
    def is_camera_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∫–∞–º–µ—Ä—ã"""
        return self.camera_handler.camera is not None
    
    def is_mediapipe_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ MediaPipe Tasks"""
        return self.gesture_recognizer.recognizer is not None
    
    def list_cameras(self) -> List[int]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä"""
        available_cameras = []
        print("üìπ –ü–æ–∏—Å–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–º–µ—Ä—ã –æ—Ç 0 –¥–æ 10
        for i in range(11):
            try:
                cap = cv2.VideoCapture(i)
                if cap.isOpened():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ–º –ª–∏ –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä
                    ret, frame = cap.read()
                    if ret and frame is not None:
                        available_cameras.append(i)
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–º–µ—Ä–µ
                        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        fps = cap.get(cv2.CAP_PROP_FPS)
                        
                        print(f"   ‚úì –ö–∞–º–µ—Ä–∞ {i}: {width}x{height} @ {fps:.1f}fps")
                    
                cap.release()
            except Exception:
                continue
        
        if available_cameras:
            print(f"üìπ –ù–∞–π–¥–µ–Ω–æ –∫–∞–º–µ—Ä: {len(available_cameras)} - {available_cameras}")
        else:
            print("‚ùå –ö–∞–º–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            
        return available_cameras
    
    def switch_camera(self, camera_id: int) -> bool:
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –¥—Ä—É–≥—É—é –∫–∞–º–µ—Ä—É"""
        available_cameras = self.list_cameras()
        
        if camera_id not in available_cameras:
            print(f"‚ùå –ö–∞–º–µ—Ä–∞ {camera_id} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {available_cameras}")
            return False
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â–∏–π –∞–Ω–∞–ª–∏–∑
        was_running = self.is_vision_active
        if was_running:
            self.stop_real_time_analysis()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config.camera_device_id = camera_id
        
        # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–º–µ—Ä—É
        self.camera_handler.release()
        self.camera_handler = CameraHandler(self.config)
        
        # –í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑, –µ—Å–ª–∏ –æ–Ω –±—ã–ª –∑–∞–ø—É—â–µ–Ω
        if was_running:
            success = self.start_real_time_analysis()
            if success:
                print(f"üìπ –ü–µ—Ä–µ–∫–ª—é—á–∏–ª–∏—Å—å –Ω–∞ –∫–∞–º–µ—Ä—É {camera_id}")
            return success
        else:
            print(f"üìπ –ö–∞–º–µ—Ä–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∞ –Ω–∞ {camera_id}")
            return True
    
    def get_current_camera(self) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–µ–∫—É—â–µ–π –∫–∞–º–µ—Ä—ã"""
        return self.config.camera_device_id
    
    def refresh_cameras(self) -> List[int]:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–∞–º–µ—Ä"""
        return self.list_cameras()
    
    def get_current_frame(self) -> Optional[np.ndarray]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞ —Å –∫–∞–º–µ—Ä—ã"""
        return self.camera_handler.get_current_frame()
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.stop_real_time_analysis()
        self.camera_handler.release()
        self.gesture_recognizer.close()

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üëÅÔ∏è  –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ vision –º–æ–¥—É–ª—è —Å MediaPipe Tasks...")
    
    vision_handler = VisionHandler()
    
    if vision_handler.is_camera_available():
        print("\nüìπ –¢–µ—Å—Ç –∫–∞–º–µ—Ä—ã –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤:")
        
        if vision_handler.is_mediapipe_available():
            vision_handler.start_real_time_analysis()
            
            try:
                # –¢–µ—Å—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥
                print("–ü–æ–∫–∞–∂–∏—Ç–µ —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∂–µ—Å—Ç—ã –ø–µ—Ä–µ–¥ –∫–∞–º–µ—Ä–æ–π...")
                time.sleep(10)
                
                # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞
                analysis = vision_handler.analyze_single_frame()
                print(f"–ê–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–∞: {analysis}")
                
                # –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                recent = vision_handler.get_recent_analysis()
                print(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∞–Ω–∞–ª–∏–∑—ã: {len(recent)}")
                
                # –¢–µ–∫—É—â–∏–µ –∂–µ—Å—Ç—ã
                current = vision_handler.get_current_gestures()
                print(f"–¢–µ–∫—É—â–∏–µ –∂–µ—Å—Ç—ã: {len(current)}")
                
            finally:
                vision_handler.cleanup()
        else:
            print("‚ùå MediaPipe Tasks –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å gesture_recognizer.task")
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")