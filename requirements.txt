# LLM inference библиотеки
# llama-cpp-python==0.2.90
# Поддержка CUDA для GPU ускорения (Я использовал колеса llama_cpp_python-0.3.9-cp310-cp310-win_amd64.whl, так проще установка, но в GitHub приложить не могу)
llama-cpp-python[cublas] # Раскомментировать если нужна CUDA поддержка

# Web Framework
Flask>=3.0.0  # Веб-фреймворк для REST API

# Вспомогательные библиотеки
colorama==0.4.6  # Для цветного вывода в консоль
psutil==5.9.8    # Для мониторинга системных ресурсов
typing-extensions==4.12.2  # Для типизации

# Аудио библиотеки
pyaudio>=0.2.11  # Для записи и воспроизведения аудио
SpeechRecognition>=3.10.0  # Для распознавания речи
pyttsx3>=2.90  # Для синтеза речи
pydub>=0.25.1  # Для обработки аудио файлов
requests>=2.31.0  # Для HTTP запросов к API

# Vision библиотеки
opencv-python>=4.8.0  # Для работы с камерой и обработки видео
Pillow>=10.0.0  # Для обработки изображений
numpy>=1.24.0  # Для работы с массивами изображений
mediapipe>=0.10.0  # Для продвинутой детекции жестов

# GUI библиотеки
PyQt5>=5.15.0  # Для графического интерфейса
PyOpenGL>=3.1.0  # Для 3D графики (опционально)
PyOpenGL-accelerate>=3.1.0  # Ускорение OpenGL (опционально)

# Опциональные библиотеки для расширенной функциональности
# torch>=2.0.0  # Для vLLM (если потребуется)
# vllm>=0.5.0   # Альтернативная библиотека для инференса