# 🤖 AI-Консультант «Транснефть»

**Проект:** «Транснефть — Технологии»  
**Разработчик:** Денисов Виталий Евгениевич, Левчук Валерия Сергеевна  
**Организация:** ПАО «Транснефть»

---

## 📹 Видеопрезентация

https://github.com/user-attachments/assets/aaf842ed-6884-4f4b-ba7d-508f62f3c490

---
P.s. Голос вырезался, как и озвучка, но она есть.
## 📋 Содержание

1. [Описание проекта](#-описание-проекта)
2. [Технологический стек](#-технологический-стек)
3. [Архитектура проекта](#-архитектура-проекта)
4. [Структура файлов](#-структура-файлов)
5. [Ключевые компоненты](#-ключевые-компоненты)
6. [Установка и запуск](#-установка-и-запуск)
7. [Конфигурация](#-конфигурация)
8. [Использование](#-использование)
9. [Технические детали](#-технические-детали)
10. [Особенности реализации](#-особенности-реализации)

---

## 🎯 Описание проекта

**AI-Консультант «Транснефть»** — это интеллектуальная система на базе локальной языковой модели **Qwen3-4B-Thinking**, предназначенная для ответа на вопросы о компании ПАО «Транснефть». Система оснащена интерактивным 3D-персонажем с анимациями, поддержкой голосового ввода, озвучивания ответов и распознавания жестов.

### Основные возможности

- ✅ **Локальная AI модель** — работает без интернета, полная конфиденциальность данных
- ✅ **Режим "Thinking"** — модель показывает процесс рассуждений перед ответом
- ✅ **3D персонаж** — интерактивный анимированный консультант с 4 анимациями
- ✅ **Голосовой ввод** — распознавание речи с автоматическим определением пауз
- ✅ **Озвучивание ответов** — синтез речи на русском языке
- ✅ **Распознавание жестов** — управление через камеру (MediaPipe)
- ✅ **База знаний** — структурированная информация о компании Транснефть
- ✅ **Веб-интерфейс** — современный responsive дизайн с поддержкой всех функций

---

## 🛠 Технологический стек

### Backend

- **Python 3.10+** — основной язык разработки
- **llama-cpp-python** — инференс GGUF моделей с GPU поддержкой
- **Flask** — веб-фреймворк для API
- **MediaPipe** — распознавание жестов рук
- **SpeechRecognition** — распознавание речи (Google API)
- **pyttsx3** — синтез речи (Text-to-Speech)
- **OpenCV** — обработка видео с камеры
- **NumPy** — обработка массивов данных

### Frontend

- **HTML5 + CSS3** — структура и стилизация
- **JavaScript (ES6+)** — логика приложения
- **Three.js** — 3D рендеринг персонажа
- **GLTFLoader** — загрузка 3D моделей
- **Server-Sent Events (SSE)** — стриминг ответов от AI

### AI модель

- **Qwen3-4B-Thinking** (abliterated, Q4_K_S квантизация)
- **Thinking mode** — модель показывает процесс рассуждения
- **Контекст:** 32K токенов
- **Квантизация:** Q4_K_S (оптимальный баланс качества и скорости)

### 3D Assets

- **Blender** — создание и обработка 3D модели
- **Mixamo** — источник анимаций персонажа
- **glTF/GLB формат** — оптимизированный формат для веба

---

## 🏗 Архитектура проекта

```
┌─────────────────────────────────────────────────────────────┐
│                    WEB ИНТЕРФЕЙС (Browser)                  │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │  3D Character│  │  Chat UI     │  │  Controls    │      │
│  │  (Three.js)  │  │  (Messages)  │  │  (Voice/Cam) │      │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘      │
│         │                 │                 │              │
└─────────┼─────────────────┼─────────────────┼──────────────┘
          │                 │                 │
          │         AJAX/SSE│                 │
          │                 ▼                 │
┌─────────┼─────────────────────────────────────────────┐
│         │         FLASK WEB SERVER (web_app.py)       │
│         │    ┌─────────────────────────────────┐      │
│         │    │  /api/chat (SSE streaming)      │      │
│         │    │  /api/voice/start, /stop        │      │
│         │    │  /api/camera/start, /stop       │      │
│         │    │  /api/tts/speak                 │      │
│         │    └─────────────┬───────────────────┘      │
│         │                  │                          │
│         └──────────────────┼──────────────────────────┤
│                            ▼                          │
│         ┌──────────────────────────────────────────┐  │
│         │     CORE MODULES (Python Backend)       │  │
│         ├──────────────────────────────────────────┤  │
│         │  main.py         - LLM Engine            │  │
│         │  audio_handler   - Voice I/O             │  │
│         │  vision_handler  - Camera + Gestures     │  │
│         │  chat_logger     - Logging               │  │
│         │  config.py       - Configuration         │  │
│         └─────────┬────────────────────────────────┘  │
└───────────────────┼───────────────────────────────────┘
                    ▼
        ┌───────────────────────────────┐
        │   LLAMA.CPP (C++ Backend)     │
        │   ┌───────────────────────┐   │
        │   │  Qwen3-4B-Thinking    │   │
        │   │  Model (GGUF)         │   │
        │   └───────────┬───────────┘   │
        └───────────────┼───────────────┘
                        ▼
                ┌───────────────┐
                │   GPU (CUDA)  │
                │   or CPU      │
                └───────────────┘
```

---

## 📂 Структура файлов

```
Транснефть-AI-Консультант/
│
├── 📁 3D/                              # 3D ресурсы
│   ├── Hello.fbx                       # Анимация приветствия
│   ├── Idle.fbx                        # Анимация ожидания
│   ├── Talking.fbx                     # Анимация речи
│   ├── Thinking.fbx                    # Анимация размышления
│   ├── Bot.png                         # Текстура персонажа
│   └── [исходные модели]               # Другие исходники
│
├── 📁 chat_logs/                       # Логи диалогов
│   └── *.log                           # Файлы логов с timestamps
│
├── 📁 static/                          # Статические файлы веб-приложения
│   ├── css/
│   │   └── style.css                   # Стили интерфейса (17KB)
│   ├── images/
│   │   └── Transneft.png               # Логотип компании
│   ├── js/
│   │   ├── app.js                      # Основная логика UI (27KB)
│   │   └── character3d.js              # 3D персонаж (12KB)
│   └── models/
│       └── transneft_character.glb     # 3D модель с анимациями
│
├── 📁 templates/                       # HTML шаблоны
│   └── index.html                      # Главная страница
│
├── 🐍 main.py                          # Основной модуль LLM (36KB)
├── 🐍 config.py                        # Конфигурация всей системы (13KB)
├── 🐍 web_app.py                       # Flask веб-сервер (11KB)
├── 🐍 audio_handler.py                 # Голосовой ввод/вывод (26KB)
├── 🐍 vision_handler.py                # Камера и жесты (29KB)
├── 🐍 chat_logger.py                   # Логирование диалогов (4KB)
├── 🐍 import_model.py                  # Импорт 3D модели в Blender (6KB)
├── 🐍 QA.py                            # Бенчмарк по вопросам (7KB)
│
├── 📝 PROMT.md                         # База знаний о Транснефть (9KB)
├── 📝 gobench.md                       # Набор вопросов для тестирования (4KB)
├── 📝 bench.md                         # Результаты бенчмарков (5KB)
├── 📝 requirements.txt                 # Python зависимости
│
├── 🚀 install_and_run.bat              # Автоустановка и запуск (Windows)
└── 📖 README.md                        # Этот файл
```

---

## 🔑 Ключевые компоненты

### 1. **main.py** — Ядро LLM системы

**Назначение:** Загрузка, управление и инференс локальной языковой модели.

**Основные классы:**

- **`LLMConfig`** — загружает настройки из `config.py` и преобразует их в формат llama-cpp-python
- **`ThinkingLLM`** — обертка для модели с поддержкой:
  - Thinking mode (теги `<think>...</think>`)
  - История диалога с автоматической обрезкой по токенам
  - Загрузка базы знаний из PROMT.md
  - Статистика токенов и скорость генерации

**Интересные особенности:**

- **Автоматический fallback на CPU** если GPU недоступен
- **KV-cache квантизация (Q8_0)** для экономии VRAM
- **Flash Attention** для ускорения генерации
- **Полная выгрузка на GPU** (`-1` layers) для максимальной скорости
- **Обрезка истории** — оставляет только последние N токенов, чтобы не превышать контекст

**Пример использования:**

```python
from main import ThinkingLLM, LLMConfig

config = LLMConfig()  # Загрузка из config.py
llm = ThinkingLLM(config)

response = llm.generate_response("Когда основана Транснефть?")
print(response['thinking'])  # Процесс размышления
print(response['answer'])    # Финальный ответ
```

---

### 2. **config.py** — Централизованная конфигурация

**Назначение:** Единая точка настройки ВСЕХ параметров системы.

**Секции:**

1. **Модель LLM** — путь к GGUF, контекст, GPU layers
2. **Память и оптимизация** — MMAP, MLOCK, KV-cache, Flash Attention
3. **Генерация текста** — temperature, top-p, top-k, max tokens
4. **Голосовой ввод (STT)** — движок, язык, пороги тишины
5. **Озвучивание (TTS)** — движок, голос, скорость, громкость
6. **Камера и жесты** — разрешение, FPS, уверенность детекции
7. **Отладка** — verbose логи, показ thinking

**Интересные параметры:**

```python
# Автоматическое отключение микрофона после 5 сек тишины
INACTIVITY_TIMEOUT = 5.0

# Автоматическая отправка текста после 2 сек паузы в речи
SILENCE_THRESHOLD = 2.0

# Увеличение скорости TTS на 20% для более быстрой речи
TTS_RATE = 150  # → реально 180 слов/мин
```

---

### 3. **web_app.py** — Flask веб-сервер

**Назначение:** REST API для фронтенда с поддержкой стриминга.

**Основные эндпоинты:**

| Эндпоинт | Метод | Описание |
|----------|-------|----------|
| `/` | GET | Главная страница |
| `/api/chat` | POST | Генерация ответа (SSE streaming) |
| `/api/voice/start` | POST | Запуск распознавания голоса |
| `/api/voice/stop` | POST | Остановка записи |
| `/api/voice/get-text` | GET | Получение распознанного текста (polling) |
| `/api/tts/speak` | POST | Озвучивание текста |
| `/api/camera/start` | POST | Запуск камеры и жестов |
| `/api/camera/stop` | POST | Остановка камеры |
| `/api/gesture/get-text` | GET | Получение распознанных жестов |
| `/api/reset` | POST | Сброс истории диалога |

**Интересные особенности:**

- **SSE стриминг** — ответы передаются по предложениям в реальном времени
- **Long polling** — фронтенд опрашивает текст из голоса/жестов каждые 500ms
- **Автопауза жестов** — распознавание приостанавливается на время обработки AI
- **Callback система** — голос и жесты используют колбэки для передачи данных

**Логика работы голосового ввода:**

```
1. Пользователь нажимает 🎤
2. Backend запускает непрерывную запись
3. Каждые 500ms фронтенд опрашивает /api/voice/get-text
4. При обнаружении 2 сек тишины → текст распознается
5. Текст автоматически отправляется в /api/chat
6. После ответа AI → запись возобновляется
7. Если 5 сек нет речи → автоматическое отключение
```

---

### 4. **audio_handler.py** — Голосовой ввод/вывод

**Назначение:** Распознавание речи и синтез голоса.

**Основные классы:**

- **`AudioConfig`** — загрузка настроек из config.py
- **`SpeechRecognizer`** — распознавание речи (Google API)
- **`TextToSpeech`** — синтез речи (pyttsx3)
- **`AudioHandler`** — объединяет STT и TTS

**Интересные особенности:**

- **Автоматический выбор мужского голоса** — ищет русские мужские голоса в системе
- **Непрерывная запись с таймерами:**
  - 2 сек тишины → конец фразы → распознавание
  - 5 сек без речи → полное отключение
- **Увеличение скорости речи на 20%** — `TTS_RATE * 1.2` для более естественного темпа
- **Очистка текста от эмодзи** перед озвучкой (регулярные выражения)
- **Асинхронная озвучка** — не блокирует основной поток

**Пример:**

```python
from audio_handler import AudioHandler

audio = AudioHandler()

# Голосовой ввод
text = audio.listen_for_question(timeout=10)
print(f"Распознано: {text}")

# Озвучивание ответа
audio.speak_answer("Транснефть основана в 1993 году", play_async=True)
```

---

### 5. **vision_handler.py** — Камера и распознавание жестов

**Назначение:** Работа с камерой и детекция жестов рук через MediaPipe Tasks.

**Основные классы:**

- **`VisionConfig`** — конфигурация камеры и MediaPipe
- **`MediaPipeGestureRecognizer`** — распознавание жестов (MediaPipe Tasks API)
- **`CameraHandler`** — захват видео с камеры
- **`VisionHandler`** — объединяет камеру и распознавание

**Поддерживаемые жесты:**

| Жест | Команда | Текст для AI |
|------|---------|--------------|
| ✋ Open Palm | Приветствие | "Привет" |
| ✌️ Victory | Победа | "Победа" |
| 👍 Thumb Up | Одобрение | "Супер" |
| ☝️ Pointing Up | Внимание | "Внимание" |

**Интересные особенности:**

- **Система подтверждения** — жест должен повторяться 3+ раза за 1.5 сек
- **Автоматический таймаут** — камера отключается через 7 сек без жестов
- **Пауза на время обработки AI** — жесты не распознаются пока AI отвечает
- **MediaPipe Tasks API** — новейший API с лучшей производительностью

**Логика работы:**

```
1. Захват кадра с камеры (16 FPS)
2. Пропуск кадров (frame_skip=2) для экономии CPU
3. Детекция жестов через MediaPipe
4. Добавление в буфер жестов (1.5 сек окно)
5. Если жест повторился ≥3 раз → подтверждение
6. Отправка текста через callback в веб-приложение
```

---

### 6. **chat_logger.py** — Логирование диалогов

**Назначение:** Сохранение истории диалогов в файлы.

**Формат лога:**

```
================================================================================
CHAT LOG - AI-Консультант ПАО «Транснефть»
Дата начала сессии: 2025-10-18 19:30:45
================================================================================

────────────────────────────────────────────────────────────────────────────────
[19:30:52] 💬 ПОЛЬЗОВАТЕЛЬ (text):
Когда основана Транснефть?

[19:30:53] 💭 AI РАЗМЫШЛЕНИЯ (Thinking):
Пользователь спрашивает о дате основания компании...

[19:30:54] 🤖 AI ОТВЕТ:
ПАО «Транснефть» было учреждено 14 августа 1993 года...
```

**Особенности:**

- **Автоматические имена файлов** с timestamp
- **Разделение thinking и answer** для анализа
- **Метки источника** — text/voice/gesture
- **Статистика сессии** — время начала/завершения

---

### 7. **app.js** — Логика веб-интерфейса

**Назначение:** Управление UI, отправка запросов, обработка стриминга.

**Основной класс:** `TransneftAssistant`

**Ключевые методы:**

- `sendMessage(source)` — отправка сообщения AI через SSE
- `toggleVoice()` — включение/выключение микрофона
- `toggleCamera()` — включение/выключение камеры
- `toggleSpeaker()` — включение/выключение автоозвучки
- `startVoicePolling()` — опрос распознанного текста
- `startGesturePolling()` — опрос жестов

**Интересные особенности:**

- **SSE стриминг** — ответы обновляются в реальном времени
- **Long polling** — опрос голоса/жестов каждые 500ms
- **Автовозобновление** — голос и жесты автоматически возобновляются после ответа
- **Markdown рендеринг** — поддержка жирного текста, кода, списков
- **Typing индикатор** — анимация при генерации ответа

**SSE обработка:**

```javascript
const response = await fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({ message, source })
});

const reader = response.body.getReader();
while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    // Обработка events: thinking, answer, done
    if (data.type === 'thinking') {
        showThinking(data.content);
    } else if (data.type === 'answer') {
        updateMessage(data.content);
    }
}
```

---

### 8. **character3d.js** — 3D персонаж

**Назначение:** Загрузка и управление 3D моделью с анимациями.

**Основной класс:** `Character3D`

**Анимации:**

1. **Hello** — приветственный жест (разовая)
2. **Idle** — спокойное ожидание (цикл)
3. **Thinking** — размышление с планшетом (цикл)
4. **Talking** — жестикуляция при ответе (цикл)

**Логика переключения:**

```
Загрузка → Hello (1 раз) → Idle (цикл)
                              ↓
Вопрос → Thinking (цикл) → Talking (цикл) → Idle (возврат)
```

**Интересные особенности:**

- **Автоматический масштаб** — модель нормализуется до высоты 2 единицы
- **Центрирование** — модель автоматически центрируется по X/Z
- **Таймер Idle** — через 5 сек без действий запускается Idle анимация
- **Плавные переходы** — `fadeOut()` для смены анимаций
- **Responsive** — адаптируется к размеру окна

**Three.js настройки:**

```javascript
// Камера
position: [0, 2, 5]  // Выше и дальше от модели
lookAt: [0, 1.7, 0]  // Смотрит чуть выше центра

// Освещение
AmbientLight: 1.0    // Общее освещение
DirectionalLight: 1.5 // Направленный свет
FillLight: 0.5       // Боковая подсветка
```

---

### 9. **PROMT.md** — База знаний

**Назначение:** Структурированная информация о компании Транснефть.

**Разделы:**

1. **Инструкция для AI** — типы вопросов и соответствующие ответы
2. **Информация о компании** — даты, структура капитала
3. **Основные направления деятельности**
4. **Ключевые организации** — реестродержатель, аудитор
5. **Корпоративное управление** — органы управления, комитеты
6. **Крупные проекты** — ВСТО, БТС-2, КТК и др. (с деталями)
7. **Историческая хронология** — от 1863 до 2019
8. **Интересные факты** — рекорды, технические характеристики

**Объем:** ~9KB текста, охватывает 17 вопросов бенчмарка

**Автозагрузка:** main.py автоматически загружает PROMT.md в системный промпт

---

### 10. **QA.py** — Бенчмарк система

**Назначение:** Автоматическое тестирование LLM на 17 вопросах из `gobench.md`.

**Функции:**

- Парсинг вопросов из markdown
- Последовательная генерация ответов
- Логирование thinking + answer в файл
- Валидация (проверка что все 17 вопросов найдены)

**Пример вопроса:**

```markdown
**1. Когда была основана компания ПАО «Транснефть»?**
```

**Формат лога бенчмарка:**

```
================================================================================
QA BENCHMARK - Тестирование LLM по вопросам о ПАО «Транснефть»
Дата запуска: 2025-10-18 20:00:00
Модель: .../Qwen3-4B-Thinking-abliterated.Q4_K_S.gguf
Количество вопросов: 17
================================================================================

================================================================================
📋 ВОПРОС 1/17
================================================================================
Когда была основана компания ПАО «Транснефть»?
────────────────────────────────────────────────────────────────────────────────
💭 РАЗМЫШЛЕНИЯ:
[thinking content]
────────────────────────────────────────────────────────────────────────────────
✅ ОТВЕТ:
[answer content]
```

**Запуск:**

```bash
python QA.py
```

---

### 11. **import_model.py** — Импорт 3D модели

**Назначение:** Blender скрипт для импорта FBX анимаций и экспорта в GLB.

**Процесс:**

1. Очистка сцены Blender
2. Импорт базовой модели `Idle.fbx` (с скелетом)
3. Применение текстуры `Bot.png`
4. Импорт остальных анимаций: Hello, Talking, Thinking
5. Привязка модели к скелету (если нужно)
6. Экспорт в `static/models/transneft_character.glb`

**Особенности:**

- Автоматическая совместимость с Blender 3.x и 4.x
- Проверка привязки модели к скелету
- Валидация всех анимаций перед экспортом
- Вывод размера итогового GLB файла

**Запуск в Blender:**

```bash
blender --background --python import_model.py
```

---

## 🚀 Установка и запуск

### Автоматическая установка (Windows)

1. **Создайте файл `install_and_run.bat`:**

```batch
@echo off
echo ========================================
echo AI-Консультант Транснефть
echo Автоустановка и запуск
echo ========================================
echo.

REM Проверка наличия Python
python --version >nul 2>&1
if errorlevel 1 (
    echo ОШИБКА: Python не найден!
    echo Установите Python 3.10+ с python.org
    pause
    exit /b 1
)

REM Создание виртуального окружения (если нет)
if not exist "venv" (
    echo Создание виртуального окружения...
    python -m venv venv
)

REM Активация виртуального окружения
echo Активация виртуального окружения...
call venv\Scripts\activate.bat

REM Установка зависимостей
echo Установка зависимостей...
pip install --upgrade pip
pip install -r requirements.txt

REM Запуск веб-приложения
echo.
echo ========================================
echo Запуск веб-сервера...
echo Откройте браузер: http://localhost:5000
echo ========================================
echo.
python web_app.py

pause
```

2. **Запустите `install_and_run.bat`**

### Ручная установка

#### Шаг 1: Установка Python

Требуется **Python 3.10+**

Скачать: https://www.python.org/downloads/

#### Шаг 2: Клонирование репозитория

```bash
git clone https://github.com/your-username/transneft-ai-consultant.git
cd transneft-ai-consultant
```

#### Шаг 3: Создание виртуального окружения

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

#### Шаг 4: Установка зависимостей

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Для GPU поддержки (NVIDIA CUDA):**

```bash
pip install llama-cpp-python[cublas] --force-reinstall --no-cache-dir
```

#### Шаг 5: Скачивание модели

Скачайте **Qwen3-4B-Thinking** (abliterated, Q4_K_S):

```
https://huggingface.co/mradermacher/Huihui-Qwen3-4B-Thinking-2507-abliterated-GGUF
```

Файл: `Huihui-Qwen3-4B-Thinking-2507-abliterated.Q4_K_S.gguf`

#### Шаг 6: Настройка конфигурации

Отредактируйте `config.py`:

```python
# Укажите путь к скачанной модели
MODEL_PATH = "путь/к/Qwen3-4B-Thinking.gguf"

# Настройте GPU (если есть)
GPU_LAYERS = -1  # -1 = все слои на GPU
MAIN_GPU = 0     # Индекс основного GPU
```

#### Шаг 7: Запуск

**Веб-интерфейс:**

```bash
python web_app.py
```

Откройте: http://localhost:5000

**Консольный режим:**

```bash
python main.py
```

---

## ⚙️ Конфигурация

Все настройки находятся в **`config.py`**

### Основные параметры

```python
# ═══════════════════════════════════════
# МОДЕЛЬ
# ═══════════════════════════════════════
MODEL_PATH = "путь/к/модели.gguf"
CONTEXT_SIZE = 32768  # 32K токенов
GPU_LAYERS = -1       # -1 = все на GPU
BATCH_SIZE = 512      # Размер батча

# ═══════════════════════════════════════
# ГЕНЕРАЦИЯ
# ═══════════════════════════════════════
TEMPERATURE = 0.6     # Креативность (0.0-1.0)
TOP_P = 0.95         # Nucleus sampling
TOP_K = 20           # Top-K sampling
MAX_TOKENS = -1      # -1 = без ограничений

# ═══════════════════════════════════════
# ГОЛОСОВОЙ ВВОД
# ═══════════════════════════════════════
STT_ENABLED = True
STT_ENGINE = "google"           # google/whisper_api
STT_LANGUAGE = "ru-RU"
SILENCE_THRESHOLD = 2.0         # Сек тишины → отправка
INACTIVITY_TIMEOUT = 5.0        # Сек без речи → отключение
VOICE_VOLUME_THRESHOLD = 500    # Порог громкости

# ═══════════════════════════════════════
# ОЗВУЧИВАНИЕ
# ═══════════════════════════════════════
TTS_ENABLED = True
TTS_ENGINE = "pyttsx3"          # pyttsx3/elevenlabs
TTS_RATE = 150                  # Слов/мин (реально *1.2)
TTS_VOLUME = 0.9                # Громкость (0.0-1.0)
TTS_PREFER_MALE = True          # Предпочитать мужской голос

# ═══════════════════════════════════════
# КАМЕРА И ЖЕСТЫ
# ═══════════════════════════════════════
VISION_ENABLED = False          # Включить/выключить
CAMERA_DEVICE_ID = 0            # Индекс камеры
CAMERA_FPS = 16                 # Кадров в секунду
CAMERA_RESOLUTION = [640, 480]  # Разрешение
GESTURE_CONFIDENCE = 0.6        # Порог уверенности (0.0-1.0)
GESTURE_CONFIRMATION_TIME = 1.5 # Сек для подтверждения
GESTURE_INACTIVITY_TIMEOUT = 7.0 # Сек → автоотключение
```

### Оптимизация производительности

**Для слабого GPU (4-6 GB VRAM):**

```python
GPU_LAYERS = 35           # Частичная выгрузка
CONTEXT_SIZE = 16384      # Уменьшенный контекст
KV_CACHE_TYPE_K = "q4_0"  # Более агрессивная квантизация
KV_CACHE_TYPE_V = "q4_0"
```

**Для мощного GPU (12+ GB VRAM):**

```python
GPU_LAYERS = -1           # Полная выгрузка
CONTEXT_SIZE = 65536      # Большой контекст
BATCH_SIZE = 1024         # Большой батч
FLASH_ATTENTION = True    # Flash Attention
```

**Только CPU:**

```python
GPU_LAYERS = 0            # Без GPU
CONTEXT_SIZE = 16384      # Меньше контекст
BATCH_SIZE = 256          # Меньше батч
```

---

## 📖 Использование

### Веб-интерфейс

#### 1. Текстовый ввод

- Введите вопрос в поле
- Нажмите **Отправить** или **Enter**
- Наблюдайте за 3D персонажем:
  - **Thinking** — обдумывает ответ
  - **Talking** — жестикулирует при ответе
  - **Idle** — возврат в спокойное состояние

#### 2. Голосовой ввод

- Нажмите **🎤 Микрофон**
- Говорите вопрос
- **2 сек тишины** → текст автоматически отправится AI
- **5 сек без речи** → микрофон автоотключится

#### 3. Распознавание жестов

- Нажмите **📹 Камера**
- Покажите жест руками:
  - ✋ **Открытая ладонь** → "Привет"
  - ✌️ **Победа** → "Победа"
  - 👍 **Большой палец вверх** → "Супер"
  - ☝️ **Указательный палец** → "Внимание"
- Повторите жест 3+ раз для подтверждения
- Текст автоматически отправится AI

#### 4. Озвучивание ответов

- Нажмите **🔊 Динамик** для автоозвучки
- Ответы будут проговариваться вслух
- Отключите для тишины

### Консольный режим

```bash
python main.py
```

**Команды:**

- `exit`, `quit` — выход
- `clear`, `cls` — очистка истории
- `history` — показать историю диалога
- `listen` — голосовой ввод (если доступен)
- `vision start` — запуск камеры
- `vision stop` — остановка камеры
- `cameras` — список камер
- `camera <id>` — переключение камеры

### Бенчмарк

```bash
python QA.py
```

Тестирует модель на 17 вопросах из `gobench.md` и сохраняет результаты в лог-файл.

---

## 🔬 Технические детали

### Thinking Mode

Модель **Qwen3-4B-Thinking** поддерживает режим рассуждений:

```xml
<think>
Пользователь спрашивает о дате основания компании.
В базе знаний указано: учреждена 14.08.1993, 
государственная регистрация 26.08.1993.
Нужно указать обе даты для полноты ответа.
</think>

ПАО «Транснефть» было учреждено 14 августа 1993 года 
постановлением Правительства РФ №810. Государственная 
регистрация состоялась 26 августа 1993 года.
```

**Преимущества:**

- ✅ Более точные ответы
- ✅ Лучшее понимание контекста
- ✅ Меньше галлюцинаций
- ✅ Показывает логику рассуждений

**Недостаток:**

- ❌ Немного медленнее генерация (~50%-200% больше токенов)

### GPU оптимизация

**Полная выгрузка на GPU (`GPU_LAYERS = -1`):**

```
RTX 3060 (12GB): ~30 tokens/sec
RTX 4070 (12GB): ~45 tokens/sec
RTX 4090 (24GB): ~75 tokens/sec
```

**KV-cache квантизация:**

```python
KV_CACHE_TYPE_K = "q8_0"  # Экономия ~40% VRAM
KV_CACHE_TYPE_V = "q8_0"  # Минимальная потеря качества
```

**Flash Attention:**

```python
FLASH_ATTENTION = True  # +20-30% скорость
```

### Стриминг ответов

**Server-Sent Events (SSE):**

```
data: {"type": "thinking", "content": "..."}

data: {"type": "answer", "content": "Часть 1. "}

data: {"type": "answer", "content": "Часть 1. Часть 2. "}

data: {"type": "done"}
```

**Преимущества:**

- Мгновенная обратная связь
- Плавное появление текста
- Меньше воспринимаемой задержки

### Логирование

**Формат логов:**

```
chat_logs/
├── web_session.log            # Веб-интерфейс
├── chat_20251018_193045.log   # Консольный режим
└── qa_benchmark_20251018_200000.log  # Бенчмарк
```

**Содержимое:**

- Timestamp каждого сообщения
- Источник (text/voice/gesture)
- Thinking процесс
- Финальный ответ
- Статистика сессии

---

## 🎨 Особенности реализации

### 1. Автоматическое управление микрофоном

**Проблема:** Как понять, когда пользователь закончил говорить?

**Решение:**

```python
# Двухуровневая система таймеров
SILENCE_THRESHOLD = 2.0      # 2 сек тишины = конец фразы
INACTIVITY_TIMEOUT = 5.0     # 5 сек без речи = отключение

# Логика
while recording:
    if volume > THRESHOLD:
        last_speech_time = now()
        has_speech = True
    else:
        silence_duration = now() - last_speech_time
        
        if silence_duration > 2.0 and has_speech:
            # Распознать и отправить текст
            recognize_and_send()
            has_speech = False
        
        if silence_duration > 5.0:
            # Полностью отключить микрофон
            stop_recording()
```

### 2. Подтверждение жестов

**Проблема:** Избежать ложных срабатываний случайных жестов.

**Решение:**

```python
# Буфер жестов за последние 1.5 секунды
gesture_buffer = []

# Логика подтверждения
def check_confirmation():
    if len(gesture_buffer) >= 3:
        most_common = get_most_common_gesture()
        if most_common != last_confirmed:
            confirm_and_send(most_common)
            last_confirmed = most_common
```

### 3. Пауза жестов на время AI

**Проблема:** Жесты во время ответа AI могут мешать.

**Решение:**

```python
# В web_app.py
def chat():
    # Сохраняем состояние жестов
    gesture_was_active = vision_handler.is_vision_active
    
    if gesture_was_active:
        vision_handler.pause_analysis()  # Пауза (камера работает)
    
    # Генерация ответа
    yield streaming_response
    
    # Возобновляем жесты
    if gesture_was_active:
        vision_handler.resume_analysis()
```

### 4. Обрезка истории диалога

**Проблема:** История может превысить контекст модели (32K токенов).

**Решение:**

```python
def _trim_conversation_history(self):
    # Системное сообщение всегда сохраняем
    system_msgs = [m for m in history if m['role'] == 'system']
    other_msgs = [m for m in history if m['role'] != 'system']
    
    # Обрабатываем сообщения в обратном порядке (новые → старые)
    kept_msgs = []
    total_tokens = 0
    
    for msg in reversed(other_msgs):
        msg_tokens = count_tokens(msg)
        if total_tokens + msg_tokens <= max_history_tokens:
            kept_msgs.insert(0, msg)
            total_tokens += msg_tokens
        else:
            break
    
    # Обновляем историю
    self.conversation_history = system_msgs + kept_msgs
```

### 5. Адаптивная 3D модель

**Проблема:** Модели могут иметь разный размер и позицию.

**Решение:**

```javascript
// Автоматический расчет масштаба и позиции
const box = new THREE.Box3().setFromObject(model);
const size = box.getSize(new THREE.Vector3());
const center = box.getCenter(new THREE.Vector3());

// Нормализация до высоты 2 единицы
const maxSize = Math.max(size.x, size.y, size.z);
const scale = 2 / maxSize;
model.scale.set(scale, scale, scale);

// Центрирование и установка на "пол"
model.position.set(
    -center.x * scale,  // Центр по X
    0,                  // На уровне земли
    -center.z * scale   // Центр по Z
);
```

### 6. Очистка текста для TTS

**Проблема:** Эмодзи и спецсимволы вызывают ошибки озвучки.

**Решение:**

```python
import re

# Удаление эмодзи
text = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF...]', '', text)

# Замена множественных восклицательных знаков
text = re.sub(r'!+', '.', text)

# Очистка пробелов
text = re.sub(r'\s+', ' ', text).strip()
```

---

## 🏆 Преимущества системы

✅ **Полная конфиденциальность** — все работает локально, без отправки данных  
✅ **Thinking mode** — прозрачный процесс рассуждений  
✅ **Мультимодальность** — текст, голос, жесты, 3D персонаж  
✅ **GPU ускорение** — до 75 tokens/sec на RTX 4090 (5060ti - 115t/s)
✅ **Гибкая конфигурация** — все настройки в одном файле  
✅ **Расширяемость** — легко добавить новые жесты/функции  
✅ **Логирование** — полная история диалогов для анализа  

---

## 📊 Производительность

### Системные требования

**Минимальные (CPU only):**
- CPU: 4 ядра, 2.5 GHz+
- RAM: 8 GB
- Скорость: ~2-5 tokens/sec

**Рекомендованные (GPU):**
- GPU: NVIDIA GTX 1660 (6 GB VRAM) или выше
- RAM: 16 GB
- Скорость: ~20-30 tokens/sec

**Оптимальные:**
- GPU: NVIDIA RTX 4070 (12 GB VRAM) или выше
- RAM: 32 GB
- Скорость: ~45-75 tokens/sec

### Бенчмарк результаты

**Модель:** Qwen3-4B-Thinking (Q4_K_S)  
**Конфигурация:** RTX 4070, GPU_LAYERS=-1, CONTEXT=32K

| Метрика | Значение |
|---------|----------|
| Скорость генерации | 45-50 tokens/sec |
| Время загрузки модели | ~3-5 сек |
| VRAM использование | ~4.5 GB |
| Средняя длина ответа | 200-400 токенов |
| Время ответа (thinking) | 8-12 сек |
| Время ответа (instruct) | 5-8 сек |
| Точность на бенчмарке | 95%+ |

---

## 🎓 Для разработчиков

### Добавление новых жестов

**Шаг 1:** Добавьте жест в `vision_handler.py`:

```python
gesture_text_map = {
    'open_palm': 'Привет',
    'victory': 'Победа',
    'thumb_up': 'Супер',
    'pointing_up': 'Внимание',
    'closed_fist': 'Стоп',  # ← Новый жест
}
```

**Шаг 2:** Обновите описания:

```python
gesture_descriptions = {
    # ...
    "closed_fist": "✊ Кулак",
}
```

### Добавление новых анимаций

**Шаг 1:** Скачайте FBX с Mixamo  
**Шаг 2:** Поместите в папку `3D/`  
**Шаг 3:** Обновите `import_model.py`:

```python
animations = {
    "Hello": "Hello.fbx",
    "Idle": "Idle.fbx",
    "Talking": "Talking.fbx",
    "Thinking": "Thinking.fbx",
    "Waving": "Waving.fbx",  # ← Новая анимация
}
```

**Шаг 4:** Запустите импорт в Blender  
**Шаг 5:** Добавьте метод в `character3d.js`:

```javascript
startWaving() {
    this.playAnimation('Waving', true);
}
```

### Интеграция с другими моделями

**Для использования другой GGUF модели:**

1. Скачайте модель
2. Обновите `config.py`:

```python
MODEL_PATH = "путь/к/новой/модели.gguf"
```

3. Если модель не поддерживает thinking:

```python
SHOW_THINKING_TO_USER = False
```

4. Настройте параметры генерации под модель

---

## 📝 Лицензия

MIT License

---

## 👨‍💻 Автор

- Студенты РТУ МИРЭА
- **Виталий Денисов** и **Левчук Валерия**
- Проект для хакатона «Транснефть — Технологии»

---

## 🙏 Благодарности

- **Qwen Team** — за модель Qwen3-4B-Thinking
- **llama.cpp** — за быстрый инференс GGUF моделей
- **MediaPipe** — за библиотеку распознавания жестов
- **Mixamo** — за бесплатные анимации персонажей
- **Three.js** — за библиотеку 3D рендеринга
- **ПАО «Транснефть»** — за информацию о компании

---

## 📞 Поддержка

Если возникли вопросы или проблемы:

1. Проверьте [раздел конфигурации](#-конфигурация)
2. Изучите логи в `chat_logs/`
3. Проверьте консоль браузера (F12)
4. Убедитесь что модель скачана и путь правильный

---

**Приятного использования AI-Консультанта «Транснефть»! 🚀**
